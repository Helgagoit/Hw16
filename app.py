import streamlit as st
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import json
from PIL import Image
import io

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏
st.set_page_config(page_title="Fashion MNIST Classifier", layout="wide", page_icon="üëó")

# –ù–∞–∑–≤–∏ –∫–ª–∞—Å—ñ–≤ Fashion MNIST
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

class_names_ukr = ['–§—É—Ç–±–æ–ª–∫–∞', '–®—Ç–∞–Ω–∏', '–°–≤–µ—Ç—Ä', '–°—É–∫–Ω—è', '–ü–∞–ª—å—Ç–æ',
                   '–°–∞–Ω–¥–∞–ª—ñ', '–°–æ—Ä–æ—á–∫–∞', '–ö—Ä–æ—Å—ñ–≤–∫–∏', '–°—É–º–∫–∞', '–ß–µ—Ä–µ–≤–∏–∫–∏']


# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ —Ç–∞ —ñ—Å—Ç–æ—Ä—ñ—ó
@st.cache_resource
def load_model(model_name):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –º–æ–¥–µ–ª—å –∑–∞ –Ω–∞–∑–≤–æ—é"""
    model_paths = {
        '–ó–≥–æ—Ä—Ç–∫–æ–≤–∞ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–∞ (CNN)': 'fashion_mnist_cnn.keras',
        'VGG16 Transfer Learning': 'fashion_mnist_vgg16.keras'
    }
    try:
        model = tf.keras.models.load_model(model_paths[model_name])
        return model
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {e}")
        return None


@st.cache_data
def load_history(model_name):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —ñ—Å—Ç–æ—Ä—ñ—é –Ω–∞–≤—á–∞–Ω–Ω—è"""
    history_paths = {
        '–ó–≥–æ—Ä—Ç–∫–æ–≤–∞ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–∞ (CNN)': 'history_cnn.json',
        'VGG16 Transfer Learning': 'history_vgg16.json'
    }
    try:
        with open(history_paths[model_name], 'r') as f:
            return json.load(f)
    except Exception as e:
        st.warning(f"–Ü—Å—Ç–æ—Ä—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
        return None


def preprocess_image(image, model_name):
    """–ü–æ–ø–µ—Ä–µ–¥–Ω—è –æ–±—Ä–æ–±–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –º–æ–¥–µ–ª—ñ"""
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –≤ –≥—Ä–∞–¥–∞—Ü—ñ—ó —Å—ñ—Ä–æ–≥–æ
    img = image.convert('L')

    # –ó–º—ñ–Ω–∞ —Ä–æ–∑–º—ñ—Ä—É —Ç–∞ —Ñ–æ—Ä–º–∞—Ç—É –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –º–æ–¥–µ–ª—ñ
    if model_name == 'VGG16 Transfer Learning':
        # VGG16 –ø–æ—Ç—Ä–µ–±—É—î 32x32 RGB
        img = img.resize((32, 32))
        img_array = np.array(img) / 255.0
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –≤ RGB
        img_array = np.stack([img_array] * 3, axis=-1)
        img_array = np.expand_dims(img_array, axis=0)
    else:  # CNN
        # CNN –ø–æ—Ç—Ä–µ–±—É—î 28x28 grayscale
        img = img.resize((28, 28))
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=-1)
        img_array = np.expand_dims(img_array, axis=0)

    return img_array, img


def plot_training_history(history, model_name):
    """–í—ñ–¥–æ–±—Ä–∞–∂–∞—î –≥—Ä–∞—Ñ—ñ–∫–∏ –Ω–∞–≤—á–∞–Ω–Ω—è"""
    if history is None:
        st.warning("–Ü—Å—Ç–æ—Ä—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        return

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

    epochs = range(1, len(history['accuracy']) + 1)

    # –ì—Ä–∞—Ñ—ñ–∫ —Ç–æ—á–Ω–æ—Å—Ç—ñ
    ax1.plot(epochs, history['accuracy'], 'b-', label='–¢–æ—á–Ω—ñ—Å—Ç—å –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—ñ', linewidth=2.5, marker='o', markersize=4)
    ax1.plot(epochs, history['val_accuracy'], 'g-', label='–¢–æ—á–Ω—ñ—Å—Ç—å –Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó', linewidth=2.5, marker='s',
             markersize=4)
    ax1.set_title(f'–¢–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ ({model_name})', fontsize=14, fontweight='bold')
    ax1.set_xlabel('–ï–ø–æ—Ö–∏', fontsize=12)
    ax1.set_ylabel('–¢–æ—á–Ω—ñ—Å—Ç—å', fontsize=12)
    ax1.legend(fontsize=11)
    ax1.grid(True, alpha=0.3, linestyle='--')
    ax1.set_ylim([0.7, 1.0])

    # –ì—Ä–∞—Ñ—ñ–∫ –≤—Ç—Ä–∞—Ç
    ax2.plot(epochs, history['loss'], 'r--', label='–í—Ç—Ä–∞—Ç–∏ –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—ñ', linewidth=2.5, marker='o', markersize=4)
    ax2.plot(epochs, history['val_loss'], 'orange', linestyle='--', label='–í—Ç—Ä–∞—Ç–∏ –Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó', linewidth=2.5,
             marker='s', markersize=4)
    ax2.set_title(f'–í—Ç—Ä–∞—Ç–∏ –º–æ–¥–µ–ª—ñ ({model_name})', fontsize=14, fontweight='bold')
    ax2.set_xlabel('–ï–ø–æ—Ö–∏', fontsize=12)
    ax2.set_ylabel('–í—Ç—Ä–∞—Ç–∏', fontsize=12)
    ax2.legend(fontsize=11)
    ax2.grid(True, alpha=0.3, linestyle='--')

    plt.tight_layout()
    return fig


def predict_image(model, img_array):
    """–†–æ–±–∏—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è"""
    predictions = model.predict(img_array, verbose=0)
    return predictions[0]


# ============ –ì–û–õ–û–í–ù–ê –ß–ê–°–¢–ò–ù–ê –ó–ê–°–¢–û–°–£–ù–ö–£ ============

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.markdown("""
    <h1 style='text-align: center; color: #2E86AB;'>
        üëó Fashion MNIST –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä
    </h1>
    <h3 style='text-align: center; color: #666;'>
        –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑–≥–æ—Ä—Ç–∫–æ–≤–æ—ó –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂—ñ —Ç–∞ VGG16
    </h3>
""", unsafe_allow_html=True)

st.markdown("---")

# –ë—ñ—á–Ω–∞ –ø–∞–Ω–µ–ª—å
st.sidebar.header("‚öôÔ∏è –í–∏–±—ñ—Ä –º–æ–¥–µ–ª—ñ")

model_name = st.sidebar.radio(
    "–û–±–µ—Ä—ñ—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó:",
    ['–ó–≥–æ—Ä—Ç–∫–æ–≤–∞ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–∞ (CNN)', 'VGG16 Transfer Learning'],
    help="–û–±–µ—Ä—ñ—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –∑–æ–±—Ä–∞–∂–µ–Ω—å"
)

# –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–¥–µ–ª—ñ
model_info = {
    '–ó–≥–æ—Ä—Ç–∫–æ–≤–∞ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–∞ (CNN)': {
        'icon': 'üß†',
        'description': '–ó–≥–æ—Ä—Ç–∫–æ–≤–∞ –º–µ—Ä–µ–∂–∞ –∑ 3 Conv2D —à–∞—Ä–∞–º–∏, MaxPooling —Ç–∞ Dense —à–∞—Ä–∞–º–∏',
        'architecture': '3 Conv2D ‚Üí 2 MaxPooling ‚Üí Flatten ‚Üí Dense',
        'accuracy': '~91.83%',
        'parameters': '93,322',
        'training_time': '~3 —Ö–≤ 35 —Å–µ–∫',
        'input_size': '28√ó28 (grayscale)',
        'advantages': '–®–≤–∏–¥–∫–∞, –∫–æ–º–ø–∞–∫—Ç–Ω–∞, –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ –¥–ª—è –ø—Ä–æ—Å—Ç–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å'
    },
    'VGG16 Transfer Learning': {
        'icon': 'üéØ',
        'description': 'Transfer Learning –Ω–∞ –±–∞–∑—ñ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–æ—ó VGG16 –∑ ImageNet',
        'architecture': 'VGG16 (frozen) ‚Üí GlobalAveragePooling ‚Üí Dense ‚Üí BatchNorm ‚Üí Dropout',
        'accuracy': '~88.0%',
        'parameters': 'VGG16 (14.7M)',
        'training_time': '~1 –≥–æ–¥ 25 —Ö–≤',
        'input_size': '32√ó32 (RGB)',
        'advantages': '–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω—ñ –≤–∞–≥–∏, –ø–æ—Ç—É–∂–Ω—ñ –æ–∑–Ω–∞–∫–∏'
    }
}

current_info = model_info[model_name]

st.sidebar.markdown(f"""
### {current_info['icon']} –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–¥–µ–ª—å

**–û–ø–∏—Å:**  
{current_info['description']}

**–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞:**  
`{current_info['architecture']}`

**–ú–µ—Ç—Ä–∏–∫–∏:**
- üìä –¢–æ—á–Ω—ñ—Å—Ç—å: `{current_info['accuracy']}`
- üî¢ –ü–∞—Ä–∞–º–µ—Ç—Ä–∏: `{current_info['parameters']}`
- ‚è±Ô∏è –ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: `{current_info['training_time']}`
- üìê –†–æ–∑–º—ñ—Ä –≤—Ö–æ–¥—É: `{current_info['input_size']}`

**–ü–µ—Ä–µ–≤–∞–≥–∏:**  
{current_info['advantages']}
""")

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –æ–±—Ä–∞–Ω–æ—ó –º–æ–¥–µ–ª—ñ
model = load_model(model_name)

if model is not None:
    # –í–∫–ª–∞–¥–∫–∏
    tab1, tab2, tab3 = st.tabs(["üìä –Ü—Å—Ç–æ—Ä—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è", "üñºÔ∏è –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –∑–æ–±—Ä–∞–∂–µ–Ω—å", "üîç –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª—ñ"])

    # ============ –í–ö–õ–ê–î–ö–ê 1: –Ü–°–¢–û–†–Ü–Ø –ù–ê–í–ß–ê–ù–ù–Ø ============
    with tab1:
        st.header(f"üìà –ì—Ä–∞—Ñ—ñ–∫–∏ –Ω–∞–≤—á–∞–Ω–Ω—è - {model_name}")

        history = load_history(model_name)
        if history:
            # –ì—Ä–∞—Ñ—ñ–∫–∏
            fig = plot_training_history(history, model_name)
            st.pyplot(fig)

            st.markdown("---")

            # –ú–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
            st.subheader("üìä –§—ñ–Ω–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏")
            col1, col2, col3, col4 = st.columns(4)

            final_train_acc = history['accuracy'][-1]
            final_val_acc = history['val_accuracy'][-1]
            final_train_loss = history['loss'][-1]
            final_val_loss = history['val_loss'][-1]

            with col1:
                st.metric(
                    "–¢–æ—á–Ω—ñ—Å—Ç—å (—Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è)",
                    f"{final_train_acc:.4f}",
                    delta=f"{final_train_acc - history['accuracy'][0]:.4f}"
                )
            with col2:
                st.metric(
                    "–¢–æ—á–Ω—ñ—Å—Ç—å (–≤–∞–ª—ñ–¥–∞—Ü—ñ—è)",
                    f"{final_val_acc:.4f}",
                    delta=f"{final_val_acc - history['val_accuracy'][0]:.4f}"
                )
            with col3:
                st.metric(
                    "–í—Ç—Ä–∞—Ç–∏ (—Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è)",
                    f"{final_train_loss:.4f}",
                    delta=f"{final_train_loss - history['loss'][0]:.4f}",
                    delta_color="inverse"
                )
            with col4:
                st.metric(
                    "–í—Ç—Ä–∞—Ç–∏ (–≤–∞–ª—ñ–¥–∞—Ü—ñ—è)",
                    f"{final_val_loss:.4f}",
                    delta=f"{final_val_loss - history['val_loss'][0]:.4f}",
                    delta_color="inverse"
                )

            # –î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
            st.markdown("---")
            col1, col2 = st.columns(2)

            with col1:
                st.info(f"""
                **üìå –ö—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ø–æ—Ö:** {len(history['accuracy'])}  
                **üéØ –ù–∞–π–∫—Ä–∞—â–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å (val):** {max(history['val_accuracy']):.4f}  
                **üìâ –ù–∞–π–º–µ–Ω—à—ñ –≤—Ç—Ä–∞—Ç–∏ (val):** {min(history['val_loss']):.4f}
                """)

            with col2:
                overfitting = final_train_acc - final_val_acc
                if overfitting > 0.05:
                    st.warning(f"""
                    ‚ö†Ô∏è **–ú–æ–∂–ª–∏–≤–µ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è**  
                    –†—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ—é —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–æ—é —Ç–æ—á–Ω—ñ—Å—Ç—é: {overfitting:.4f}
                    """)
                else:
                    st.success(f"""
                    ‚úÖ **–ú–æ–¥–µ–ª—å –Ω–∞–≤—á–µ–Ω–∞ –¥–æ–±—Ä–µ**  
                    –†—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ—é —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–æ—é —Ç–æ—á–Ω—ñ—Å—Ç—é: {overfitting:.4f}
                    """)

    # ============ –í–ö–õ–ê–î–ö–ê 2: –ö–õ–ê–°–ò–§–Ü–ö–ê–¶–Ü–Ø ============
    with tab2:
        st.header(f"üñºÔ∏è –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –∑–æ–±—Ä–∞–∂–µ–Ω—å - {model_name}")

        col1, col2 = st.columns([1, 1])

        with col1:
            st.subheader("üì§ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è")

            uploaded_file = st.file_uploader(
                "–û–±–µ—Ä—ñ—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –æ–¥—è–≥—É",
                type=['png', 'jpg', 'jpeg', 'bmp'],
                help="–ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏: PNG, JPG, JPEG, BMP"
            )

            if uploaded_file is not None:
                image = Image.open(uploaded_file)
                st.image(image, caption="–û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", use_container_width=True)

                # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                st.info(f"**–†–æ–∑–º—ñ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è:** {image.size[0]}√ó{image.size[1]} –ø—ñ–∫—Å–µ–ª—ñ–≤")

                # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
                if st.button("üîç –ö–ª–∞—Å–∏—Ñ—ñ–∫—É–≤–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è", type="primary", use_container_width=True):
                    with st.spinner("üîÑ –û–±—Ä–æ–±–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è..."):
                        # –ü–æ–ø–µ—Ä–µ–¥–Ω—è –æ–±—Ä–æ–±–∫–∞
                        img_array, processed_img = preprocess_image(image, model_name)

                        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
                        predictions = predict_image(model, img_array)
                        predicted_class = np.argmax(predictions)
                        confidence = predictions[predicted_class] * 100

                        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
                        st.session_state['predictions'] = predictions
                        st.session_state['predicted_class'] = predicted_class
                        st.session_state['confidence'] = confidence
                        st.session_state['processed_img'] = processed_img
                        st.session_state['model_used'] = model_name

                        st.success("‚úÖ –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

        with col2:
            if 'predictions' in st.session_state:
                st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó")

                # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –æ–±—Ä–æ–±–ª–µ–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                input_size = "32√ó32 RGB" if st.session_state[
                                                'model_used'] == 'VGG16 Transfer Learning' else "28√ó28 Grayscale"
                st.image(
                    st.session_state['processed_img'],
                    caption=f"–û–±—Ä–æ–±–ª–µ–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è ({input_size})",
                    width=200
                )

                # –û—Å–Ω–æ–≤–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                predicted_idx = st.session_state['predicted_class']
                st.markdown(f"""
                    <div style='background-color: #d4edda; padding: 20px; border-radius: 10px; border: 2px solid #28a745;'>
                        <h2 style='color: #155724; margin: 0;'>üéØ –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–∏–π –∫–ª–∞—Å</h2>
                        <h1 style='color: #155724; margin: 10px 0;'>{class_names[predicted_idx]}</h1>
                        <h3 style='color: #155724; margin: 0;'>{class_names_ukr[predicted_idx]}</h3>
                        <h2 style='color: #155724; margin-top: 10px;'>–í–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å: {st.session_state['confidence']:.2f}%</h2>
                    </div>
                """, unsafe_allow_html=True)

                st.markdown("---")

                # –ì—Ä–∞—Ñ—ñ–∫ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π
                st.subheader("üìä –†–æ–∑–ø–æ–¥—ñ–ª –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π")

                fig, ax = plt.subplots(figsize=(10, 8))

                # –ö–æ–ª—å–æ—Ä–∏ –¥–ª—è –≥—Ä–∞—Ñ—ñ–∫–∞
                colors = ['#28a745' if i == predicted_idx else '#17a2b8' for i in range(10)]

                # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –≥—Ä–∞—Ñ—ñ–∫–∞
                y_pos = np.arange(len(class_names))
                bars = ax.barh(y_pos, st.session_state['predictions'] * 100, color=colors, alpha=0.8, edgecolor='black')

                ax.set_yticks(y_pos)
                ax.set_yticklabels([f"{class_names[i]}\n({class_names_ukr[i]})" for i in range(10)], fontsize=10)
                ax.set_xlabel('–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å (%)', fontsize=12, fontweight='bold')
                ax.set_title('–ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –¥–ª—è –≤—Å—ñ—Ö –∫–ª–∞—Å—ñ–≤', fontsize=14, fontweight='bold', pad=20)
                ax.grid(axis='x', alpha=0.3, linestyle='--')
                ax.set_xlim([0, 105])

                # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –Ω–∞ –≥—Ä–∞—Ñ—ñ–∫
                for i, (bar, prob) in enumerate(zip(bars, st.session_state['predictions'])):
                    width = bar.get_width()
                    label = f'{prob * 100:.2f}%'
                    ax.text(width + 1, bar.get_y() + bar.get_height() / 2,
                            label, ha='left', va='center', fontsize=10, fontweight='bold')

                plt.tight_layout()
                st.pyplot(fig)

                # –î–µ—Ç–∞–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è
                st.subheader("üìã –î–µ—Ç–∞–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π")

                import pandas as pd

                results_data = []
                for i in range(10):
                    results_data.append({
                        '‚Ññ': i,
                        '–ö–ª–∞—Å (English)': class_names[i],
                        '–ö–ª–∞—Å (–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞)': class_names_ukr[i],
                        '–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å (%)': f"{st.session_state['predictions'][i] * 100:.2f}",
                        '–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è': '‚úÖ –¢–∞–∫' if i == predicted_idx else '‚ùå –ù—ñ'
                    })

                df = pd.DataFrame(results_data)
                st.dataframe(
                    df,
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "‚Ññ": st.column_config.NumberColumn("‚Ññ", width="small"),
                        "–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å (%)": st.column_config.TextColumn("–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å (%)", width="medium"),
                    }
                )
            else:
                st.info("üëÜ –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–∞ –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å –∫–Ω–æ–ø–∫—É '–ö–ª–∞—Å–∏—Ñ—ñ–∫—É–≤–∞—Ç–∏' –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")

    # ============ –í–ö–õ–ê–î–ö–ê 3: –ê–†–•–Ü–¢–ï–ö–¢–£–†–ê ============
    with tab3:
        st.header(f"üîç –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª—ñ - {model_name}")

        # –í–∏–≤–µ–¥–µ–Ω–Ω—è –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ –º–æ–¥–µ–ª—ñ
        st.subheader("üìê –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ—ó –º–µ—Ä–µ–∂—ñ")

        string_buffer = io.StringIO()
        model.summary(print_fn=lambda x: string_buffer.write(x + '\n'))
        model_summary = string_buffer.getvalue()

        st.code(model_summary, language='text')

        st.markdown("---")

        # –û–ø–∏—Å –∫–ª–∞—Å—ñ–≤
        st.subheader("üìö –ö–ª–∞—Å–∏ Fashion MNIST")

        col1, col2 = st.columns(2)

        for i, (eng, ukr) in enumerate(zip(class_names, class_names_ukr)):
            if i < 5:
                col1.markdown(f"**{i}.** {eng} - *{ukr}*")
            else:
                col2.markdown(f"**{i}.** {eng} - *{ukr}*")

        st.markdown("---")

        # –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
        st.subheader("‚öñÔ∏è –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π")

        comparison_data = {
            '–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞': [
                '–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞',
                '–¢–æ—á–Ω—ñ—Å—Ç—å (Test)',
                '–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤',
                '–ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è',
                '–†–æ–∑–º—ñ—Ä –≤—Ö–æ–¥—É',
                '–¢–∏–ø –≤—Ö–æ–¥—É',
                '–ü–µ—Ä–µ–≤–∞–≥–∏',
                '–ù–µ–¥–æ–ª—ñ–∫–∏'
            ],
            '–ó–≥–æ—Ä—Ç–∫–æ–≤–∞ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–∞ (CNN)': [
                '3 Conv2D + 2 MaxPooling',
                '~91.83%',
                '93,322',
                '~3 —Ö–≤ 35 —Å',
                '28√ó28',
                'Grayscale',
                '–®–≤–∏–¥–∫–∞, –ª–µ–≥–∫–∞, –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∞',
                '–ú–µ–Ω—à–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å –Ω–∞ —Å–∫–ª–∞–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö'
            ],
            'VGG16 Transfer Learning': [
                'VGG16 + Custom layers',
                '~88.0%',
                '~15M',
                '~1 –≥–æ–¥ 25 —Ö–≤',
                '32√ó32',
                'RGB',
                '–ü–æ—Ç—É–∂–Ω—ñ –æ–∑–Ω–∞–∫–∏, transfer learning',
                '–ü–æ–≤—ñ–ª—å–Ω—ñ—à–µ –Ω–∞–≤—á–∞–Ω–Ω—è, –±—ñ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å—ñ–≤'
            ]
        }

        import pandas as pd

        df_comparison = pd.DataFrame(comparison_data)
        st.dataframe(df_comparison, use_container_width=True, hide_index=True)

else:
    st.error("""
    ‚ùå **–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å!**

    –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—è, —â–æ —Ñ–∞–π–ª–∏ –º–æ–¥–µ–ª–µ–π –∑–Ω–∞—Ö–æ–¥—è—Ç—å—Å—è –≤ —Ç—ñ–π —Å–∞–º—ñ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó, —â–æ –π app.py:
    - `fashion_mnist_cnn.keras`
    - `fashion_mnist_vgg16.keras`
    - `history_cnn.json`
    - `history_vgg16.json`
    """)

# –ù–∏–∂–Ω—ñ–π –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p><strong>Fashion MNIST –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä</strong> | –°—Ç–≤–æ—Ä–µ–Ω–æ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è CNN —Ç–∞ VGG16</p>
    <p>üõ†Ô∏è –¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó: TensorFlow 2.20 ‚Ä¢ Keras ‚Ä¢ Streamlit</p>
    <p>üìä Dataset: Fashion MNIST (60,000 train + 10,000 test images)</p>
</div>
""", unsafe_allow_html=True)